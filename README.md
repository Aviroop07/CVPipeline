# Resume Generation Pipeline

An automated resume generation system that fetches LinkedIn profile data, transforms it to JSON-Resume format, enhances it with AI processing, and generates a professional PDF resume.

## ğŸ—ï¸ Architecture

The project is built with a **modular architecture** where each major functionality is separated into dedicated modules:

### Core Modules

- **`linkedin_fetcher.py`** - LinkedIn authentication and profile data fetching
- **`linkedin_transformer.py`** - Transform LinkedIn data to JSON-Resume format
- **`openai_processor.py`** - AI-powered resume enhancement (skill filtering, categorization, ranking)
- **`pdf_generator.py`** - Professional PDF generation using borb library
- **`pipeline.py`** - Unified orchestration script that runs the complete pipeline

## ğŸš€ Quick Start

### Using the Unified Pipeline (Recommended)

```bash
# Full pipeline: LinkedIn â†’ Transform â†’ OpenAI â†’ PDF
python scripts/pipeline.py

# Skip LinkedIn fetch, use existing data
python scripts/pipeline.py --skip-linkedin

# Skip OpenAI processing
python scripts/pipeline.py --skip-openai

# Only generate PDF from existing JSON
python scripts/pipeline.py --skip-linkedin --skip-openai

# Verbose logging
python scripts/pipeline.py --verbose
```

### Using Individual Modules

```bash
# Step 1: Fetch LinkedIn data
python scripts/linkedin_fetcher.py

# Step 2: Transform to JSON-Resume format
python scripts/linkedin_transformer.py

# Step 3: Enhance with OpenAI
python scripts/openai_processor.py

# Step 4: Generate PDF
python scripts/pdf_generator.py
```

## ğŸ“‹ Prerequisites

### Dependencies

Install required packages:

```bash
pip install -r requirements.txt
```

### Environment Variables

Create a `.env` file with your credentials:

```env
# LinkedIn Authentication
LI_USER=your_linkedin_email
LI_PASS=your_linkedin_password
LI_TOTP_SECRET=your_2fa_secret  # Optional
LI_AT=your_li_at_cookie         # Preferred method
LI_JSESSIONID=your_jsessionid   # Preferred method
LI_PID=your_public_profile_id

# OpenAI API
OPENAI_API_KEY=your_openai_api_key
```

**Note**: Cookie-based authentication (`LI_AT` and `LI_JSESSIONID`) is more reliable than username/password, especially in automated environments.

## ğŸ”§ Configuration

All settings are centralized in `scripts/config.py`:

```python
# OpenAI Settings
OPENAI_MODEL = "o4-mini"
OPENAI_REASONING_EFFORT = "high"
OPENAI_TEMPERATURE = 1

# PDF Settings
PDF_FONT_SIZE = 10
PDF_HEADING_FONT_SIZE = 12
PDF_TITLE_FONT_SIZE = 14
PDF_MARGIN_TOP = 30
PDF_MARGIN_BOTTOM = 30
PDF_MARGIN_LEFT = 30
PDF_MARGIN_RIGHT = 30
PDF_SECTION_SPACING = 4

# File Names
RESUME_JSON_FILE = "resume.json"
RESUME_PDF_FILE = "Aviroop_Mitra_Resume.pdf"
LINKEDIN_RAW_FILE = "linkedin_raw.json"
```

## ğŸ“ Project Structure

```
my-resume/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ config.py                    # Centralized configuration
â”‚   â”œâ”€â”€ pipeline.py                  # ğŸ¯ Unified pipeline orchestrator
â”‚   â”œâ”€â”€ linkedin_fetcher.py          # ğŸ”— LinkedIn data fetching
â”‚   â”œâ”€â”€ linkedin_transformer.py      # ğŸ”„ Data transformation
â”‚   â”œâ”€â”€ openai_processor.py          # ğŸ¤– AI-powered enhancement
â”‚   â””â”€â”€ pdf_generator.py             # ğŸ“„ PDF generation
â”œâ”€â”€ data/
â”‚   â””â”€â”€ linkedin_raw.json            # Raw LinkedIn profile data
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ categorize_skills.txt        # AI prompt for skill categorization
â”‚   â”œâ”€â”€ extract_points.txt           # AI prompt for bullet point extraction
â”‚   â”œâ”€â”€ filter_skills.txt            # AI prompt for skill filtering
â”‚   â””â”€â”€ rank_items.txt               # AI prompt for section ranking
â”œâ”€â”€ resume.json                      # JSON-Resume formatted data
â”œâ”€â”€ Aviroop_Mitra_Resume.pdf         # Final PDF output
â””â”€â”€ requirements.txt                 # Python dependencies
```

## ğŸ¤– AI Enhancement Features

The OpenAI processor provides intelligent resume enhancement:

### Skill Processing
- **Filtering**: Removes irrelevant or duplicate skills
- **Categorization**: Groups skills into logical categories (Programming Languages, Frameworks, Cloud Technologies, etc.)
- **Ranking**: Orders skills by relevance and importance

### Content Enhancement
- **Bullet Point Extraction**: Converts long descriptions into concise bullet points
- **Section Ranking**: Reorders work experience, projects, and achievements by relevance
- **Date Formatting**: Standardizes date ranges (e.g., "Jan, 2020 â€“ Present")

### Customizable Prompts
All AI prompts are stored in the `prompts/` directory and can be customized:
- `filter_skills.txt` - Controls which skills to keep
- `categorize_skills.txt` - Defines skill categorization logic
- `rank_items.txt` - Sets ranking criteria for sections
- `extract_points.txt` - Guides bullet point extraction

## ğŸ“„ PDF Generation

The PDF generator creates professional resumes with:

- **Times New Roman** font family for professional appearance
- **Clickable hyperlinks** for LinkedIn, company, and school URLs
- **Optimized spacing** with configurable margins and section gaps
- **Italic dates** and **bold headers** for better visual hierarchy
- **Clean layout** with consistent formatting and ink blue hyperlinks
- **Unicode handling** for special characters
- **Compact content** with continuous paragraphs instead of bullet points

## ğŸ”„ GitHub Actions Workflow

The project includes automated resume updates via GitHub Actions:

```yaml
# .github/workflows/update-resume.yml
# Runs daily at 09:00 IST or manually via workflow_dispatch
# Uses the unified pipeline.py for streamlined execution
```

## ğŸ› ï¸ Development

### Adding New Modules

To add new functionality:

1. Create a new module in `scripts/`
2. Define clear functions with proper docstrings
3. Add configuration constants to `config.py`
4. Update `pipeline.py` to include the new step
5. Follow the established modular pattern

### Testing Individual Components

Each module can be imported and tested independently:

```python
from scripts.linkedin_fetcher import fetch_linkedin_data
from scripts.openai_processor import filter_skills_with_openai
from scripts.pdf_generator import create_pdf_document
```

## ğŸ“Š Pipeline Output

The pipeline provides detailed logging and progress tracking:

```
ğŸš€ Starting Resume Generation Pipeline
ğŸ“ Working directory: /path/to/resume
âš™ï¸  Configuration: LinkedIn=Fetch, OpenAI=Process

============================================================
STEP 1/4: FETCH LINKEDIN DATA
============================================================
ğŸ“ Authenticate with LinkedIn and fetch profile information
âœ… LinkedIn data fetched completed successfully

============================================================
STEP 2/4: TRANSFORM DATA  
============================================================
ğŸ“ Convert LinkedIn profile data to JSON-Resume format
âœ… Data transformation completed successfully

============================================================
STEP 3/4: OPENAI ENHANCEMENT
============================================================
ğŸ“ Filter skills, categorize, rank sections, and extract bullet points
[INFO] Filtering 56 skills via OpenAI
[INFO] Kept 24/56 skills after filtering
[INFO] Categorizing 24 skills via OpenAI
[INFO] Received 7 skill categories
âœ… OpenAI enhancement completed successfully

============================================================
STEP 4/4: GENERATE PDF
============================================================
ğŸ“ Create professional PDF resume using borb library
âœ… PDF generation completed successfully

============================================================
PIPELINE SUMMARY
============================================================
â±ï¸  Total time: 201.28 seconds
âœ… Steps completed: 4/4
ğŸ‰ Resume generation pipeline completed successfully!
ğŸ“„ PDF saved to: Aviroop_Mitra_Resume.pdf
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make changes following the modular architecture
4. Test with the pipeline script
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details. 